{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.506857Z",
     "iopub.status.busy": "2021-08-19T04:59:44.506292Z",
     "iopub.status.idle": "2021-08-19T04:59:44.513984Z",
     "shell.execute_reply": "2021-08-19T04:59:44.513041Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.506824Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pydicom\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "    \n",
    "from torch import nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.516491Z",
     "iopub.status.busy": "2021-08-19T04:59:44.515988Z",
     "iopub.status.idle": "2021-08-19T04:59:44.524201Z",
     "shell.execute_reply": "2021-08-19T04:59:44.523371Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.516455Z"
    }
   },
   "outputs": [],
   "source": [
    "# # !pip install dicom2nifti --upgrade\n",
    "# !pip install dicom2nifti\n",
    "# !pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.528137Z",
     "iopub.status.busy": "2021-08-19T04:59:44.527824Z",
     "iopub.status.idle": "2021-08-19T04:59:44.536709Z",
     "shell.execute_reply": "2021-08-19T04:59:44.535798Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.528111Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.540392Z",
     "iopub.status.busy": "2021-08-19T04:59:44.540070Z",
     "iopub.status.idle": "2021-08-19T04:59:44.548944Z",
     "shell.execute_reply": "2021-08-19T04:59:44.548104Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.540360Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "channels = ['FLAIR','T1w','T1wCE','T2w']\n",
    "\n",
    "config['project_path'] = '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification'\n",
    "\n",
    "config['size'] = 256\n",
    "config['batch_size'] = 64\n",
    "config['num_workers'] = 8\n",
    "config['output_nodes'] = 1\n",
    "config['epochs'] = 10\n",
    "config['lr'] = 1e-3\n",
    "config['save_checkpoint'] = './checkpoint'\n",
    "config['min_loss'] = 1\n",
    "config['weight_decay'] = 0.0001\n",
    "config['step_size'] = 5\n",
    "config['gamma'] = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.552587Z",
     "iopub.status.busy": "2021-08-19T04:59:44.552240Z",
     "iopub.status.idle": "2021-08-19T04:59:44.566908Z",
     "shell.execute_reply": "2021-08-19T04:59:44.566072Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.552560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv',\n",
       " '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv',\n",
       " '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/test',\n",
       " '/kaggle/input/rsna-miccai-brain-tumor-radiogenomic-classification/train']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(os.path.join(config['project_path'],'*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.568711Z",
     "iopub.status.busy": "2021-08-19T04:59:44.568372Z",
     "iopub.status.idle": "2021-08-19T04:59:44.572938Z",
     "shell.execute_reply": "2021-08-19T04:59:44.571886Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.568676Z"
    }
   },
   "outputs": [],
   "source": [
    "_IMG_TRAIN = os.path.join(config['project_path'],'train')\n",
    "_WORKING = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.574885Z",
     "iopub.status.busy": "2021-08-19T04:59:44.574363Z",
     "iopub.status.idle": "2021-08-19T04:59:44.608911Z",
     "shell.execute_reply": "2021-08-19T04:59:44.608176Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.574848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BraTS21ID  MGMT_value\n",
       "0          0           1\n",
       "1          2           1\n",
       "2          3           0\n",
       "3          5           1\n",
       "4          6           1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv(os.path.join(config['project_path'],'train_labels.csv'))\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.690188Z",
     "iopub.status.busy": "2021-08-19T04:59:44.689783Z",
     "iopub.status.idle": "2021-08-19T04:59:44.722152Z",
     "shell.execute_reply": "2021-08-19T04:59:44.721231Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.690147Z"
    }
   },
   "outputs": [],
   "source": [
    "## generate absolute path to image\n",
    "def gen_fold_id(BraTS21ID):\n",
    "    std_len = 5\n",
    "    \n",
    "    BraTS21ID_str = str(BraTS21ID)\n",
    "    if len(BraTS21ID_str) < std_len:\n",
    "        app_len = std_len - len(BraTS21ID_str)\n",
    "\n",
    "        full_id = ['0']*app_len + BraTS21ID_str.split()\n",
    "        full_id_str = ''.join(full_id)\n",
    "        return full_id_str\n",
    "    else:\n",
    "        return BraTS21ID_str\n",
    "    \n",
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "def area_visiable(img_array,threshold=0.2):\n",
    "    img_area = int(img_array.shape[0])*int(img_array.shape[1])\n",
    "    non_zero_area = len(np.nonzero(img_gray)[0])\n",
    "    \n",
    "    ratio = float(non_zero_area/img_area)\n",
    "    if ratio >= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "def f1_score(preds, targets, sigmoid=True, thresh=0.5, average='micro', idx=None):\n",
    "    if sigmoid: preds = 1/(1 + np.exp(-preds))\n",
    "    preds = (preds >= thresh).astype(np.uint8)\n",
    "    if idx is not None:\n",
    "        return metrics.fbeta_score(y_true=targets, y_pred=preds, beta=1, average=None)[idx]\n",
    "    return metrics.fbeta_score(y_true=targets, y_pred=preds, beta=1, average=average)\n",
    "\n",
    "def create_metrics_DISEASE(func, name, label_cols_list):\n",
    "    return lambda preds, target: func(preds, targets, idx=label_cols_list.index(name))\n",
    "\n",
    "def classification_counts(y_pred, y_true, log=False):\n",
    "    TP,FP,TN,FN = 0,0,0,0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_true[i]==y_pred[i]==1:\n",
    "            TP += 1\n",
    "        if y_pred[i]==1 and y_true[i]== 0:\n",
    "            FP += 1\n",
    "        if y_true[i]==y_pred[i]==0:\n",
    "            TN += 1\n",
    "        if y_pred[i]==0 and y_true[i]==1:\n",
    "            FN += 1\n",
    "    if log:\n",
    "        print('TP\\tFP\\tTN\\tFN\\t')\n",
    "        print(f'{TP}\\t{FP}\\t{TN}\\t{FN}\\t')\n",
    "    return {'TP': TP, 'FP': FP, 'TN': TN, 'FN': FN}\n",
    "\n",
    "def binary_metrics(y_pred, y_true, log=False):\n",
    "    precision = metrics.precision_score(y_true, y_pred, average='binary')\n",
    "    recall = metrics.recall_score(y_true, y_pred, average='binary')\n",
    "    spec = metrics.recall_score(y_true, y_pred, average='binary', pos_label=0)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, average='binary')\n",
    "    f2 = metrics.fbeta_score(y_true, y_pred, average='binary', beta=2)\n",
    "    auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "    acc = metrics.accuracy_score(y_true, y_pred)\n",
    "    if log:\n",
    "        print('pre\\trecall\\tspec\\tacc\\tauc\\tf2\\tf1\\t')\n",
    "        print(f'{precision:0.4f}\\t{recall:0.4f}\\t{spec:0.4f}\\t{acc:0.4f}\\t{auc:0.4f}\\t{f2:0.4f}\\t{f1:0.4f}')\n",
    "    return {\n",
    "        'precision': precision, 'recall': recall, 'specificity': spec, \n",
    "        'accuracy': acc, 'auc': auc, 'f2': f2, 'f1': f1 \n",
    "    }\n",
    "\n",
    "def report_binary_thresholded_metrics(y_pred, y_true, thresh_step=0.1, lite=True):\n",
    "    report = pd.DataFrame(columns=['precision', 'recall', 'specificity', \n",
    "                                   'accuracy', 'auc', 'f2', 'f1', 'TP', 'FP', 'TN', 'FN'])\n",
    "    preds = y_pred\n",
    "    for thresh in np.arange(thresh_step, 1.00, thresh_step):\n",
    "        y_pred = (preds >= thresh).astype(np.uint8).squeeze()\n",
    "        metrics = binary_metrics(y_pred, y_true, log=False)\n",
    "        counts = classification_counts(y_pred, y_true, log=False)\n",
    "        row = pd.DataFrame.from_dict({f'{thresh:0.2f}': dict(metrics, **counts)}, orient='index')\n",
    "        report = pd.concat([report, row], ignore_index=False)\n",
    "        report.index.name = 'threshold'\n",
    "    if lite:\n",
    "        report = report[['precision', 'recall', 'specificity', \n",
    "                        'f1', 'TP', 'FP', 'TN', 'FN']]\n",
    "    return report\n",
    "\n",
    "def save_checkpoint(model, save_path, channel, epoch):\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "            'model': best_model,\n",
    "            'epoch':epoch+1,\n",
    "            'model_state_dict':best_model.state_dict(),\n",
    "            'optimizer_state_dict':best_optimizer.state_dict(),\n",
    "            'scheduler_state_dict':best_scheduler.state_dict()\n",
    "            }\n",
    "    \"\"\"\n",
    "#     d = date.today().strftime(\"%m_%d_%Y\") \n",
    "#     h = datetime.now().strftime(\"%H_%M_%S\").split('_')\n",
    "#     h_offset = int(datetime.now().strftime(\"%H_%M_%S\").split('_')[0])+7\n",
    "#     h[0] = str(h_offset)\n",
    "#     h = '_'.join(h)\n",
    "#     today_time = d +'_'+h\n",
    "# #     today_time = date.today().strftime(\"%m_%d_%Y\") + '_' + datetime.now().strftime(\"%H_%M\")\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    \n",
    "    if not os.path.isdir(os.path.join(save_path,channel)):\n",
    "        os.mkdir(os.path.join(save_path,channel))\n",
    "    \n",
    "    checkpoint = {\n",
    "            'model': model,\n",
    "            'epoch':epoch,\n",
    "            'model_state_dict':model.state_dict()\n",
    "            }\n",
    "    f = os.path.join(os.path.join(save_path,channel), 'best_checkpoint.pth')\n",
    "    torch.save(checkpoint, f)\n",
    "    print('Saved checkpoint')\n",
    "    \n",
    "\n",
    "def evaluation(model,epoch,test_dataloader,criterion,device):\n",
    "    model.eval()\n",
    "    batch_losses = []\n",
    "    with torch.no_grad():\n",
    "        model_result = []\n",
    "        targets = []\n",
    "        for imgs, targets_batch in tqdm(test_dataloader):\n",
    "            imgs, targets_batch = imgs.to(device), targets_batch.to(device)\n",
    "\n",
    "            model_batch_result = model(imgs)\n",
    "            model_result.extend(model_batch_result.cpu().numpy())\n",
    "            targets.extend(targets_batch.cpu().numpy())\n",
    "            \n",
    "            loss = criterion(model_batch_result, targets_batch.type(torch.float))\n",
    "            batch_loss_value = loss.item()\n",
    "            batch_losses.append(batch_loss_value)\n",
    "            \n",
    "    loss_value = np.mean(batch_losses)\n",
    "    df_report = report_binary_thresholded_metrics(model_result,targets)\n",
    "    model.train()\n",
    "\n",
    "    return df_report,loss_value\n",
    "    \n",
    "\n",
    "def load_checkpoint(filepath):\n",
    "    \n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.724437Z",
     "iopub.status.busy": "2021-08-19T04:59:44.724046Z",
     "iopub.status.idle": "2021-08-19T04:59:44.740173Z",
     "shell.execute_reply": "2021-08-19T04:59:44.739381Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.724392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Simple dataloader and label binarization, that is converting test labels into binary arrays of length 27 (number of classes) with 1 in places of applicable labels).\n",
    "# from torch.utils.data.dataset import Dataset\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from PIL import ImageFile\n",
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, df_data, transforms=None):\n",
    "        \"\"\"\n",
    "        param:\n",
    "            data_path: is path of images\n",
    "            anno_path: is path of dataframe\n",
    "            classes_path: is path of h5 classes\n",
    "            \n",
    "            transform:\n",
    "            \n",
    "        return:\n",
    "            \n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.imgs = df_data['path']\n",
    "#         self.annos = df_data['target']        \n",
    "        self.annos = [np.array([item],dtype=float) for item in list(df_data['target'])]\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        anno = self.annos[item]\n",
    "#         img_path = os.path.join(self.data_path, self.imgs[item])\n",
    "#         img = Image.open(img_path).convert('RGB')\n",
    "        img_gray = load_dicom(self.imgs[item])\n",
    "        img_3d = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "        img = Image.fromarray(img_3d)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, anno\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "class customTestDataset(Dataset):\n",
    "    def __init__(self, df_data, transforms=None):\n",
    "        \"\"\"\n",
    "        param:\n",
    "            data_path: is path of images\n",
    "            anno_path: is path of dataframe\n",
    "            classes_path: is path of h5 classes\n",
    "            \n",
    "            transform:\n",
    "            \n",
    "        return:\n",
    "            \n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.imgs = df_data['path']\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        img_gray = load_dicom(self.imgs[item])\n",
    "        img_3d = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)\n",
    "        img = Image.fromarray(img_3d)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "# import torch\n",
    "class customNet(nn.Module):\n",
    "    def __init__(self, output_nodes):\n",
    "        super().__init__()\n",
    "        resnet = models.resnext50_32x4d(pretrained=True)\n",
    "        feature_size = 256\n",
    "        resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=resnet.fc.in_features, out_features=feature_size),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(in_features=feature_size, out_features=output_nodes)\n",
    "        )\n",
    "        self.base_model = resnet\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigm(self.base_model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.742858Z",
     "iopub.status.busy": "2021-08-19T04:59:44.742436Z",
     "iopub.status.idle": "2021-08-19T04:59:44.751926Z",
     "shell.execute_reply": "2021-08-19T04:59:44.751036Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.742819Z"
    }
   },
   "outputs": [],
   "source": [
    "def single_process(idx):\n",
    "    train_labels = pd.read_csv(os.path.join(config['project_path'],'train_labels.csv'))\n",
    "    \n",
    "    channels = ['FLAIR','T1w','T1wCE','T2w']\n",
    "\n",
    "    fold_id = gen_fold_id(train_labels.iloc[idx]['BraTS21ID'])\n",
    "    \n",
    "    label = train_labels.iloc[idx]['MGMT_value']\n",
    "    \n",
    "#     nii_fold_id = os.path.join(_WORKING,'nifti',fold_id)\n",
    "    \n",
    "#     dict_anno = {}\n",
    "    \n",
    "#     if not os.path.isdir(nii_fold_id):\n",
    "#         os.mkdir(nii_fold_id)\n",
    "        \n",
    "#     list_nii_file = []\n",
    "    list_anno = []\n",
    "    \n",
    "    for channel in channels:\n",
    "#         try:\n",
    "#         dicom_directory = os.path.join(_IMG_TRAIN,fold_id,channel)\n",
    "        dicom_directory = glob(os.path.join(_IMG_TRAIN,fold_id,channel,'*.dcm'))\n",
    "        \n",
    "        for img in dicom_directory:\n",
    "            dict_anno = {}\n",
    "            dict_anno['path'] = img\n",
    "            dict_anno['target'] = label\n",
    "            dict_anno['channel'] = channel\n",
    "            list_anno.append(dict_anno)\n",
    "    \n",
    "#         nii_file = os.path.join(nii_fold_id, channel.lower()+'.nii.gz')\n",
    "\n",
    "#         dicom2nifti.dicom_series_to_nifti(dicom_directory, nii_file, reorient_nifti=False)\n",
    "\n",
    "#         list_nii_file.append(nii_file)\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     dict_anno['image'] = list_nii_file\n",
    "#     dict_anno['label'] = label\n",
    "    \n",
    "#     return dict_anno\n",
    "    return list_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:44.753993Z",
     "iopub.status.busy": "2021-08-19T04:59:44.753623Z",
     "iopub.status.idle": "2021-08-19T04:59:56.007983Z",
     "shell.execute_reply": "2021-08-19T04:59:56.006823Z",
     "shell.execute_reply.started": "2021-08-19T04:59:44.753956Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 585/585 [00:11<00:00, 52.53it/s]\n"
     ]
    }
   ],
   "source": [
    "list_anno = []\n",
    "\n",
    "# nii_fold = os.path.join(_WORKING,'nifti')\n",
    "# if not os.path.isdir(nii_fold):\n",
    "#     os.mkdir(nii_fold)\n",
    "\n",
    "pool = mp.Pool(8)\n",
    "list_idx = range(len(train_labels))\n",
    "for anno in tqdm(pool.imap_unordered(single_process,list_idx),total=len(list_idx)):\n",
    "#     list_anno.append(anno)\n",
    "    list_anno += anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:56.010734Z",
     "iopub.status.busy": "2021-08-19T04:59:56.010097Z",
     "iopub.status.idle": "2021-08-19T04:59:56.496884Z",
     "shell.execute_reply": "2021-08-19T04:59:56.496085Z",
     "shell.execute_reply.started": "2021-08-19T04:59:56.010684Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>target</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/rsna-miccai-brain-tumor-radiogen...</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/rsna-miccai-brain-tumor-radiogen...</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/rsna-miccai-brain-tumor-radiogen...</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/rsna-miccai-brain-tumor-radiogen...</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/rsna-miccai-brain-tumor-radiogen...</td>\n",
       "      <td>1</td>\n",
       "      <td>FLAIR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  target channel\n",
       "0  /kaggle/input/rsna-miccai-brain-tumor-radiogen...       1   FLAIR\n",
       "1  /kaggle/input/rsna-miccai-brain-tumor-radiogen...       1   FLAIR\n",
       "2  /kaggle/input/rsna-miccai-brain-tumor-radiogen...       1   FLAIR\n",
       "3  /kaggle/input/rsna-miccai-brain-tumor-radiogen...       1   FLAIR\n",
       "4  /kaggle/input/rsna-miccai-brain-tumor-radiogen...       1   FLAIR"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_anno = pd.DataFrame([])\n",
    "# df_anno = pd.DataFrame(list_anno)\n",
    "# df_anno['path'] = list_anno\n",
    "# df_anno['target'] = list(anno_train['MGMT_value'])\n",
    "# anno_train.iloc[-1]\n",
    "# len(list_anno)\n",
    "df_full_channel = pd.DataFrame(list_anno)\n",
    "df_full_channel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:56.498534Z",
     "iopub.status.busy": "2021-08-19T04:59:56.498183Z",
     "iopub.status.idle": "2021-08-19T04:59:56.512281Z",
     "shell.execute_reply": "2021-08-19T04:59:56.511070Z",
     "shell.execute_reply.started": "2021-08-19T04:59:56.498497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    195789\n",
       "0    152852\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_channel['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:56.514115Z",
     "iopub.status.busy": "2021-08-19T04:59:56.513737Z",
     "iopub.status.idle": "2021-08-19T04:59:56.518073Z",
     "shell.execute_reply": "2021-08-19T04:59:56.516879Z",
     "shell.execute_reply.started": "2021-08-19T04:59:56.514077Z"
    }
   },
   "outputs": [],
   "source": [
    "# channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-19T04:59:56.521058Z",
     "iopub.status.busy": "2021-08-19T04:59:56.520680Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:1554: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Amount current training and validation\n",
      "1    34711\n",
      "0    24687\n",
      "Name: target, dtype: int64 1    8659\n",
      "0    6191\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6f0490667142c69fe92ebdc469b816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/95.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Current channel: FLAIR\n",
      "Current epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 928/928 [21:17<00:00,  1.38s/it]\n",
      "100%|██████████| 233/233 [01:51<00:00,  2.08it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/928 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint\n",
      "Current performance:  precision      0.604409\n",
      "recall         0.845363\n",
      "specificity    0.226135\n",
      "f1             0.704863\n",
      "TP                 7320\n",
      "FP                 4791\n",
      "TN                 1400\n",
      "FN                 1339\n",
      "Name: 0.50, dtype: object\n",
      "Current learning rate:  0.001\n",
      "Current training loss:  0.684184262721703\n",
      "**********\n",
      "Current channel: FLAIR\n",
      "Current epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 124/928 [02:55<18:18,  1.37s/it]"
     ]
    }
   ],
   "source": [
    "for channel in channels:\n",
    "    config['channel'] = channel\n",
    "    \n",
    "    df_anno = df_full_channel[df_full_channel['channel']==config['channel']]\n",
    "\n",
    "    x = list(df_anno['path'])\n",
    "    y = list(df_anno['target'])\n",
    "    xtrain, xval, ytrain, yval = train_test_split(x,y, test_size=0.2,random_state=25, shuffle=True)\n",
    "\n",
    "    df_train = pd.DataFrame([])\n",
    "    df_train['path'] = xtrain\n",
    "    df_train['target'] = ytrain\n",
    "\n",
    "    df_val = pd.DataFrame([])\n",
    "    df_val['path'] = xval\n",
    "    df_val['target'] = yval\n",
    "\n",
    "    list_record_train = df_train.to_dict('record')\n",
    "    list_record_valid = df_val.to_dict('record')\n",
    "    print('#'*20)\n",
    "    print('Amount current training and validation')\n",
    "    print(df_train['target'].value_counts(),df_val['target'].value_counts())\n",
    "\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((int(config['size']), int(config['size']))),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((int(config['size']), int(config['size']))),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "    train_ds = customDataset(df_train, train_transform)\n",
    "\n",
    "    val_ds = customDataset(df_val, val_transform)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "                                train_ds, \n",
    "                                batch_size=config['batch_size'], \n",
    "                                num_workers=config['num_workers'], \n",
    "                                shuffle=True,\n",
    "                                drop_last=True\n",
    "                                )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "                        val_ds, \n",
    "                        batch_size=config['batch_size'], \n",
    "                        num_workers=config['num_workers']\n",
    "                        )\n",
    "\n",
    "    model = customNet(config['output_nodes'])\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    criterion = nn.BCELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, \n",
    "        step_size=int(config['step_size']), \n",
    "        gamma= config['gamma'], \n",
    "        last_epoch=-1\n",
    "        )\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        print('*'*10)\n",
    "        print('Current channel: {}'.format(channel))\n",
    "        print('Current epoch: {}'.format(str(epoch)))\n",
    "\n",
    "        batch_losses = []\n",
    "        for imgs, targets in tqdm(train_dataloader):\n",
    "            imgs, targets = imgs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            model_result = model(imgs)\n",
    "            loss = criterion(model_result, targets.type(torch.float))\n",
    "\n",
    "            batch_loss_value = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(batch_loss_value)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        df_eval,loss_val = evaluation(model,epoch,test_dataloader,criterion,device)\n",
    "\n",
    "        loss_value = np.mean(batch_losses)\n",
    "\n",
    "        if loss_value < config['min_loss']:\n",
    "            config['min_loss'] = loss_value\n",
    "            save_checkpoint(model, config['save_checkpoint'], config['channel'], epoch)\n",
    "        \n",
    "        print('Current performance: ',df_eval.iloc[4])\n",
    "        print('Current learning rate: ',optimizer.param_groups[0]['lr'])\n",
    "        print('Current training loss: ',loss_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
